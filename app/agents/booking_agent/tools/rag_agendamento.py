"""
Agente de agendamento mÃ©dico â€“ versÃ£o modificada
Cidade Ã© passada por fora do prompt do usuÃ¡rio.
"""

from __future__ import annotations
import  json, asyncio
from typing import List, Optional


from langgraph.graph import StateGraph, END

from pydantic import BaseModel
from app.llm_factory import get_llm_provider

# â”€â”€â”€ configuraÃ§Ã£o de tracing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


# â”€â”€â”€ especialidades & cidades suportadas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ESPECIALIDADES = {"nutrologo", "psiquiatra", "psicologo"}
CIDADES = {"sao-paulo", "recife", "fortaleza"}

# â”€â”€â”€ funÃ§Ã£o de scraping (jÃ¡ fornecida) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from app.agents.booking_agent.tools.scrape_module import scrape_medicos

# â”€â”€â”€ estado do workflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class QueryState(BaseModel):
    prompt: str
    cidade: Optional[str] = None
    especialidade: Optional[str] = None
    medicos: Optional[List[dict]] = None
    reply: Optional[str] = None

# â”€â”€â”€ LLM para parsing de entrada â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
llm = get_llm_provider('openai')
# Nova versÃ£o do schema: extrai apenas a especialidade
FC_SCHEMA = {
    "name": "extrair_especialidade",
    "description": "Extrai apenas a especialidade desejada pelo usuÃ¡rio.",
    "parameters": {
        "type": "object",
        "properties": {
            "especialidade": {"type": "string"},
        },
        "required": ["especialidade"],
    },
}

# â”€â”€â”€ nÃ³s do grafo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_input(st: QueryState) -> QueryState:
    """Extrai apenas a especialidade do prompt."""
    resp = llm.invoke(
        [{"role": "user", "content": st.prompt}],
        functions=[FC_SCHEMA],
        function_call="auto",
    )
    if "function_call" in resp.additional_kwargs:
        args = json.loads(resp.additional_kwargs["function_call"]["arguments"])
        st.especialidade = args["especialidade"].lower().strip()
    return st

def validate(st: QueryState) -> QueryState:
    """Valida cidade e especialidade fornecidas."""
    if st.cidade not in CIDADES:
        st.reply = (
            f"Desculpe, ainda nÃ£o tenho informaÃ§Ãµes para a cidade â€œ{st.cidade}â€.\n"
            f"Cidades disponÃ­veis: {', '.join(sorted(CIDADES))}."
        )
    elif st.especialidade not in ESPECIALIDADES:
        st.reply = (
            f"Desculpe, ainda nÃ£o tenho informaÃ§Ãµes sobre a especialidade "
            f"â€œ{st.especialidade}â€.\nEspecialidades disponÃ­veis: "
            f"{', '.join(sorted(ESPECIALIDADES))}."
        )
    return st

def buscar_medicos(st: QueryState) -> QueryState:
    """Executa o scraping de mÃ©dicos."""
    st.medicos = scrape_medicos(st.cidade, st.especialidade)[:5]
    return st

def format_reply(st: QueryState) -> QueryState:
    """Formata a resposta final ao usuÃ¡rio."""
    if st.reply:
        return st
    if not st.medicos:
        st.reply = (
            f"Nenhum profissional de {st.especialidade.title()} encontrado em "
            f"{st.cidade.replace('-', ' ').title()} com o convÃªnio solicitado."
        )
    else:
        linhas = [
            f"{i+1}. {m['nome']} â€“ {m['endereco']} "
            #f"(CRM {m['crm'] or 'â€”'})"
            for i, m in enumerate(st.medicos)
        ]
        st.reply = (
            f"Eis alguns profissionais de **{st.especialidade.title()}** em "
            f"**{st.cidade.replace('-', ' ').title()}**:\n\n" + "\n".join(linhas)
        )
    return st

# â”€â”€â”€ construÃ§Ã£o do grafo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
g = StateGraph(QueryState)
g.add_node("PARSE", parse_input)
g.add_node("VALIDATE", validate)
g.add_node("BUSCAR", buscar_medicos)
g.add_node("RESPONDER", format_reply)

g.set_entry_point("PARSE")

g.add_edge("PARSE", "VALIDATE")
g.add_conditional_edges("VALIDATE", lambda s: "RESPONDER" if s.reply else "BUSCAR")
g.add_edge("BUSCAR", "RESPONDER")
g.add_edge("RESPONDER", END)

agent = g.compile()

# â”€â”€â”€ interface CLI com entrada separada de cidade â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def run_cli() -> None:
    cidade = input("ğŸŒ† Informe a cidade (ex: sao-paulo):\n> ").lower().strip()
    prompt = input("ğŸ‘¤ Qual especialista vocÃª procura?\n> ")
    st = QueryState(prompt=prompt, cidade=cidade)
    st = QueryState.model_validate(await agent.ainvoke(st))
    print("\nğŸ¤– " + (st.reply or "Ocorreu um erro inesperado."))

if __name__ == "__main__":
    asyncio.run(run_cli())
